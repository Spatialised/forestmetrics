{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forest structure using PDAL + Python\n",
    "\n",
    "Dr Adam Steer, November 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NODATA_VALUE = -9999\n",
    "LCF_HEIGHTS = [0, 0.05, 0.5, 1, 2, 3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pdal\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import shapely\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry import MultiPolygon\n",
    "from shapely.geometry import box\n",
    "#from shapely.strtree import STRtree\n",
    "\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import osmnx as ox\n",
    "\n",
    "import os\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('../'))\n",
    "sys.path.insert(0, os.path.abspath('../../callingelvis'))\n",
    "\n",
    "# not using this, using geopandas instead\n",
    "from rtree import index\n",
    "\n",
    "# this is needed to create a raster from the output array\n",
    "from osgeo import gdal\n",
    "import osgeo.osr as osr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from callingelvis import anybodyhome\n",
    "\n",
    "import forestmetrics.forestmetrics as metrics\n",
    "import forestmetrics.utils as forestutils\n",
    "\n",
    "#import forestpipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tern_products(metadata, points, sindex, resolution, lasfile, outpath):\n",
    "    \"\"\"\n",
    "    Wrapper to iterate over the input data and generate rasters for each product.\n",
    "    \n",
    "    *note this part could be paralellised - maybe per-product, or per-cell\n",
    "    \n",
    "    Each grid square processed in this loop corresponds to one pixel in an output raster.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #set up an 'output resolution' sized grid - like a fishnet grid.\n",
    "    # each polygon in the resulting set covers an area of 'resolution X resolution'\n",
    "    pixel_grid = forestutils.gen_raster_cells(metadata, resolution)\n",
    "    \n",
    "    #set up output rasters\n",
    "    \n",
    "    # get tile width and height\n",
    "    tile_width = metadata[\"metadata\"][\"readers.las\"][\"maxx\"] - metadata[\"metadata\"][\"readers.las\"][\"minx\"]\n",
    "    tile_height = metadata[\"metadata\"][\"readers.las\"][\"maxy\"] - metadata[\"metadata\"][\"readers.las\"][\"miny\"]\n",
    "\n",
    "    raster_xsize = int(np.ceil(tile_width) / resolution)\n",
    "    raster_ysize = int(np.ceil(tile_height) / resolution)\n",
    "    \n",
    "    #replicate for all products...\n",
    "    vh_raster = np.zeros((raster_xsize, raster_ysize))\n",
    "    vcf_raster = np.zeros((raster_xsize, raster_ysize))\n",
    "    cth_raster = np.zeros((raster_xsize, raster_ysize))\n",
    "    cbh_raster = np.zeros((raster_xsize, raster_ysize))\n",
    "    fbf_raster = np.zeros((raster_xsize, raster_ysize))\n",
    "    cli_raster = np.zeros((raster_xsize, raster_ysize))\n",
    "    density_raster = np.zeros((raster_xsize, raster_ysize))\n",
    "    \n",
    "    veg_below_dict = {}\n",
    "\n",
    "    veg_below_dict[\"all\"] = np.zeros((raster_xsize, raster_ysize))\n",
    "    for height in LCF_HEIGHTS:\n",
    "        veg_below_dict[str(height)] = np.zeros((raster_xsize, raster_ysize))\n",
    "    \n",
    "    #internal loop around grid squares covering the LAS tile.\n",
    "    # this is another ppoint for parallelisation - since we can set up a list of geometries\n",
    "    # and cast that at multipuple processes, setting up one process per grid square\n",
    "    # another way to do this would be to recast this loop block into a function which can  \n",
    "    # be called by one process per product\n",
    "    # the second strategy seems easier, then only one process is trying to write into each\n",
    "    # output array.\n",
    "    \n",
    "    for pixel in pixel_grid:\n",
    "        \n",
    "        #compute output array index for this cell:\n",
    "        poly_x, poly_y = pixel.centroid.xy\n",
    "        \n",
    "        poly_base_x = poly_x[0] - metadata[\"metadata\"][\"readers.las\"][\"minx\"]\n",
    "        poly_base_y = poly_y[0] - metadata[\"metadata\"][\"readers.las\"][\"miny\"]\n",
    "        \n",
    "        array_x = int(np.floor((poly_base_x / (resolution)) ))\n",
    "        array_y = int(np.floor((poly_base_y / (resolution)) ))\n",
    "                \n",
    "        #get points for this cell\n",
    "        matches = forestutils.get_cell_points(pixel, points, sindex)\n",
    "        \n",
    "        #compute in order\n",
    "        #VH\n",
    "        vh_raster[array_x, array_y] = metrics.comp_vh(matches)\n",
    "        \n",
    "        #VCF\n",
    "        vcf_raster[array_x, array_y] = metrics.comp_vcf(matches)\n",
    "        \n",
    "        #LCF - long-ish process..\n",
    "        # compute a dictionary of points below height thresholds\n",
    "        veg_below = metrics.comp_veg_layers(matches, LCF_HEIGHTS)\n",
    "        \n",
    "        # add the first element of the dictionary to a raster output\n",
    "        veg_below_dict[\"all\"][array_x, array_y] = veg_below[\"all\"]\n",
    "        \n",
    "        #iterate over the height thresholds and do likewise...\n",
    "        for height in LCF_HEIGHTS:\n",
    "            veg_below_dict[str(height)][array_x, array_y] = veg_below[str(height)]\n",
    "        \n",
    "        #CTH\n",
    "        cth_raster[array_x, array_y] = metrics.comp_cth(matches)\n",
    "        \n",
    "        #CBH\n",
    "        cbh_raster[array_x, array_y] = metrics.comp_cbh(matches)\n",
    "        \n",
    "        #FBF\n",
    "        fbf_raster[array_x, array_y] = metrics.comp_fbf(matches)\n",
    "        \n",
    "        #CLI\n",
    "        cli_raster[array_x, array_y] = metrics.comp_cli(matches)\n",
    "        \n",
    "        #density\n",
    "        density_raster[array_x, array_y] = metrics.comp_density(matches, resolution)\n",
    "\n",
    "\n",
    "    #end of computing stuff, time to make outputs...\n",
    "    \n",
    "    #compute LCF values given our height thresholded veg counts\n",
    "    lcf = metrics.comp_lcf(veg_below_dict, vcf_raster)\n",
    "    \n",
    "    if (not os.path.isdir(outpath + \"/dem\")):\n",
    "        os.mkdir(outpath + \"/dem\")\n",
    "    \n",
    "    dem = forestutils.comp_dem(lasfile, outpath, resolution)\n",
    "    \n",
    "    tern_products = {}\n",
    "    tern_products[\"vh\"] = vh_raster\n",
    "    tern_products[\"vcf\"] = vcf_raster\n",
    "    tern_products[\"cth\"] = cth_raster\n",
    "    tern_products[\"cbh\"] = cbh_raster\n",
    "    tern_products[\"fbf\"] = fbf_raster\n",
    "    tern_products[\"cli\"] = cli_raster\n",
    "    tern_products[\"lcf_h\"] = lcf[\"lcf_h\"]\n",
    "    tern_products[\"lcf_os\"] = lcf[\"lcf_os\"]\n",
    "    tern_products[\"lcf_us\"] = lcf[\"lcf_us\"]\n",
    "    tern_products[\"lcf_cf\"] = lcf[\"lcf_cf\"]\n",
    "    tern_products[\"lcf_ef\"] = lcf[\"lcf_ef\"]\n",
    "    tern_products[\"lcf_nsf\"] = lcf[\"lcf_nsf\"]\n",
    "    tern_products[\"density\"] = density_raster\n",
    "\n",
    "    return(tern_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_tern_products(tern_products, metadata, resolution, lasfile, outpath):\n",
    "    \n",
    "    #set up GDAL parameters\n",
    "    \n",
    "    wktcrs = metadata[\"metadata\"][\"readers.las\"][\"comp_spatialreference\"]\n",
    "    \n",
    "    raster_parameters = {}\n",
    "    raster_parameters[\"width\"] = np.shape(tern_products[\"vh\"])[0]\n",
    "    raster_parameters[\"height\"] = np.shape(tern_products[\"vh\"])[1]\n",
    "    raster_parameters[\"upperleft_x\"] = metadata[\"metadata\"][\"readers.las\"][\"minx\"]\n",
    "    raster_parameters[\"upperleft_y\"] = metadata[\"metadata\"][\"readers.las\"][\"maxy\"]\n",
    "    raster_parameters[\"resolution\"] = resolution\n",
    "    raster_parameters[\"projection\"] = wktcrs\n",
    "    \n",
    "    fileroot = forestutils.make_file_rootname(lasfile)\n",
    "    print(fileroot)\n",
    "    \n",
    "    for productname in tern_products.keys():\n",
    "    \n",
    "        if (not os.path.isdir(os.path.join(outpath,\n",
    "                                       productname))):\n",
    "            os.mkdir(os.path.join(outpath,\n",
    "                                  productname))\n",
    "    \n",
    "    \n",
    "        #set output filenames\n",
    "        separator = \"-\"\n",
    "        \n",
    "        raster_name = separator.join([fileroot,\n",
    "                                     productname,\n",
    "                                     str(resolution) + \"m.tiff\"])\n",
    "        raster_path = os.path.join(outpath,\n",
    "                                   productname,\n",
    "                                   raster_name)\n",
    "        print(raster_path)\n",
    "        forestutils.write_product_geotiff(tern_products[productname], raster_path, raster_parameters)\n",
    "\n",
    "\n",
    "    return()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing functionality using a local file\n",
    "The following section generates metrics from a local LAZ file. Plugging in download mechanics from ELVIS will be added later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lidar test file - Mt Ainslie, chosen for varied vegetation cover and topography\n",
    "# this is pretty big, try it out if you've got more resources than my macbook pro!\n",
    "\n",
    "# thinking ahead, there will probably end up being a file splitting pre-process for \n",
    "# tiles like these... capping at say, 20 mill points. Sorting data before splitting\n",
    "# will be essential.\n",
    "\n",
    "#lasfile = \"/Volumes/Antares/ACT-lidar/8ppm/callingelvis-testdata/ACT2015_8ppm-C3-AHD_6966094_55.laz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lasfile = \"/Volumes/Antares/fire-test/NSW Government - Spatial Services-2/Point Clouds/AHD/StAlbans201709-LID2-C3-AHD_2866308_56_0002_0002/StAlbans201709-LID2-C3-AHD_2866308_56_0002_0002.las\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasfile = \"../../callingelvis-sampledata/Berridale201802-LID2-C3-AHD_6585974_55_0002_0002.las\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lasfile = \"../../callingelvis-sampledata/uncompahgre.laz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump everything from memory\n",
    "points = None\n",
    "df = None\n",
    "tern_products = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 73.9 ms, sys: 9.96 ms, total: 83.8 ms\n",
      "Wall time: 88.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "metadata = forestutils.readlasmetadata(lasfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.22 s, sys: 230 ms, total: 9.45 s\n",
      "Wall time: 9.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# this part of the process is simply reading from the source file into a Numpy \n",
    "# array. No analysis yet.\n",
    "\n",
    "points = forestutils.readlasfile(lasfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to examine LAS metadata\n",
    "#metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#points = [ points[0][\"X\"], points[0][\"Y\"], points[0][\"Z\"]]\n",
    "\n",
    "#,\"Y\",\"Z\",\"ReturnNumber\",\"NumberofReturns\",\"HeightAboveGround\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([(658000.05, 5974000.27, 1076.508,  4, 1, 2, 1, 0,  5, -19., 0, 13, 2.02784444e+08, 10.8 ),\n",
       "        (658000.2 , 5974000.79, 1066.058, 13, 1, 1, 0, 0, 12, -22., 1, 13, 2.02784444e+08, -0.41),\n",
       "        (658000.61, 5974000.71, 1066.068, 14, 1, 1, 0, 0, 12, -22., 1, 13, 2.02784444e+08,  0.36),\n",
       "        ...,\n",
       "        (659999.  , 5975998.23,  952.922, 19, 1, 1, 1, 0, 12, -19., 0, 14, 2.02785090e+08, -0.06),\n",
       "        (659998.59, 5975999.58,  952.672, 26, 1, 1, 0, 0,  2,  14., 0, 12, 2.02783264e+08,  0.  ),\n",
       "        (659999.52, 5975999.01,  952.852, 17, 1, 1, 0, 0, 12, -19., 0, 14, 2.02785090e+08,  0.08)],\n",
       "       dtype=[('X', '<f8'), ('Y', '<f8'), ('Z', '<f8'), ('Intensity', '<u2'), ('ReturnNumber', 'u1'), ('NumberOfReturns', 'u1'), ('ScanDirectionFlag', 'u1'), ('EdgeOfFlightLine', 'u1'), ('Classification', 'u1'), ('ScanAngleRank', '<f4'), ('UserData', 'u1'), ('PointSourceId', '<u2'), ('GpsTime', '<f8'), ('HeightAboveGround', '<f8')])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.3 s, sys: 387 ms, total: 18.7 s\n",
      "Wall time: 18.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#here we read points into a GeoDataFrame and dump the labelled array.\n",
    "# this is a pretty expensive step RAM wise, we're duplicating all the points...\n",
    "# df = gpd.GeoDataFrame(points)\n",
    "# ...and we're adding a geometry column... probably slows thinsg down a bit...\n",
    "\n",
    "df = forestutils.pdal2df(points)\n",
    "\n",
    "# set the points structured array to None, it isn't used anymore\n",
    "#points = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>HeightAboveGround</th>\n",
       "      <th>Classification</th>\n",
       "      <th>Intensity</th>\n",
       "      <th>ReturnNumber</th>\n",
       "      <th>NumberOfReturns</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>658000.05</td>\n",
       "      <td>5974000.27</td>\n",
       "      <td>1076.508</td>\n",
       "      <td>10.80</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>POINT (658000.050 5974000.270)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>658000.20</td>\n",
       "      <td>5974000.79</td>\n",
       "      <td>1066.058</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>POINT (658000.200 5974000.790)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>658000.61</td>\n",
       "      <td>5974000.71</td>\n",
       "      <td>1066.068</td>\n",
       "      <td>0.36</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>POINT (658000.610 5974000.710)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>658000.50</td>\n",
       "      <td>5974000.91</td>\n",
       "      <td>1066.108</td>\n",
       "      <td>0.40</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>POINT (658000.500 5974000.910)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>658000.92</td>\n",
       "      <td>5974000.82</td>\n",
       "      <td>1066.078</td>\n",
       "      <td>0.37</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>POINT (658000.920 5974000.820)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2248902</th>\n",
       "      <td>659998.26</td>\n",
       "      <td>5975998.72</td>\n",
       "      <td>952.822</td>\n",
       "      <td>0.05</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>POINT (659998.260 5975998.720)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2248903</th>\n",
       "      <td>659998.51</td>\n",
       "      <td>5975998.82</td>\n",
       "      <td>952.772</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>POINT (659998.510 5975998.820)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2248904</th>\n",
       "      <td>659999.00</td>\n",
       "      <td>5975998.23</td>\n",
       "      <td>952.922</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>POINT (659999.000 5975998.230)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2248905</th>\n",
       "      <td>659998.59</td>\n",
       "      <td>5975999.58</td>\n",
       "      <td>952.672</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>POINT (659998.590 5975999.580)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2248906</th>\n",
       "      <td>659999.52</td>\n",
       "      <td>5975999.01</td>\n",
       "      <td>952.852</td>\n",
       "      <td>0.08</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>POINT (659999.520 5975999.010)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2248907 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 X           Y         Z  HeightAboveGround  Classification  \\\n",
       "0        658000.05  5974000.27  1076.508              10.80               5   \n",
       "1        658000.20  5974000.79  1066.058              -0.41              12   \n",
       "2        658000.61  5974000.71  1066.068               0.36              12   \n",
       "3        658000.50  5974000.91  1066.108               0.40              12   \n",
       "4        658000.92  5974000.82  1066.078               0.37              12   \n",
       "...            ...         ...       ...                ...             ...   \n",
       "2248902  659998.26  5975998.72   952.822               0.05              12   \n",
       "2248903  659998.51  5975998.82   952.772               0.00               2   \n",
       "2248904  659999.00  5975998.23   952.922              -0.06              12   \n",
       "2248905  659998.59  5975999.58   952.672               0.00               2   \n",
       "2248906  659999.52  5975999.01   952.852               0.08              12   \n",
       "\n",
       "         Intensity  ReturnNumber  NumberOfReturns  \\\n",
       "0                4             1                2   \n",
       "1               13             1                1   \n",
       "2               14             1                1   \n",
       "3               12             1                1   \n",
       "4               13             1                1   \n",
       "...            ...           ...              ...   \n",
       "2248902         19             1                1   \n",
       "2248903         24             1                1   \n",
       "2248904         19             1                1   \n",
       "2248905         26             1                1   \n",
       "2248906         17             1                1   \n",
       "\n",
       "                               geometry  \n",
       "0        POINT (658000.050 5974000.270)  \n",
       "1        POINT (658000.200 5974000.790)  \n",
       "2        POINT (658000.610 5974000.710)  \n",
       "3        POINT (658000.500 5974000.910)  \n",
       "4        POINT (658000.920 5974000.820)  \n",
       "...                                 ...  \n",
       "2248902  POINT (659998.260 5975998.720)  \n",
       "2248903  POINT (659998.510 5975998.820)  \n",
       "2248904  POINT (659999.000 5975998.230)  \n",
       "2248905  POINT (659998.590 5975999.580)  \n",
       "2248906  POINT (659999.520 5975999.010)  \n",
       "\n",
       "[2248907 rows x 9 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 48s, sys: 862 ms, total: 1min 49s\n",
      "Wall time: 1min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# here we generate an RTree index on the dataframe using GeoPandas.\n",
    "# also pretty expensive... \n",
    "\n",
    "sindex = forestutils.spatialindex(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set an output resolution\n",
    "\n",
    "resolution = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "658000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata[\"metadata\"][\"readers.las\"][\"minx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([658000.2 , 658000.61, 658000.5 , 658000.92, 658000.06, 658000.22,\n",
       "       658000.13, 658000.45, 658000.48])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[0][\"X\"][1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#points2 = [points[0][\"X\"],points[0][\"Y\"],points[0][\"Z\"],points[0][\"ReturnNumber\"],points[0][\"NumberOfReturns\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 5.72 µs\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#df2 = gpd.GeoDataFrame(points2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "points2 = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/anaconda3/envs/callingelvis/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/adam/anaconda3/envs/callingelvis/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/adam/Spatialised/ANU-WALD/forestmetrics/forestmetrics/forestmetrics.py:173: RuntimeWarning: invalid value encountered in true_divide\n",
      "  veg_below[\"all\"])\n",
      "/Users/adam/Spatialised/ANU-WALD/forestmetrics/forestmetrics/forestmetrics.py:176: RuntimeWarning: invalid value encountered in true_divide\n",
      "  veg_below[\"2\"])\n",
      "/Users/adam/Spatialised/ANU-WALD/forestmetrics/forestmetrics/forestmetrics.py:179: RuntimeWarning: invalid value encountered in true_divide\n",
      "  veg_below[\"0.5\"])\n",
      "/Users/adam/Spatialised/ANU-WALD/forestmetrics/forestmetrics/forestmetrics.py:183: RuntimeWarning: invalid value encountered in true_divide\n",
      "  veg_below[\"1\"])\n",
      "/Users/adam/Spatialised/ANU-WALD/forestmetrics/forestmetrics/forestmetrics.py:185: RuntimeWarning: invalid value encountered in true_divide\n",
      "  veg_below[\"3\"])\n",
      "/Users/adam/Spatialised/ANU-WALD/forestmetrics/forestmetrics/forestmetrics.py:187: RuntimeWarning: invalid value encountered in true_divide\n",
      "  veg_below[\"all\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.2 s, sys: 132 ms, total: 44.4 s\n",
      "Wall time: 44.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#produce some rasters!\n",
    "\n",
    "tern_products = compute_tern_products(metadata, df, sindex, resolution, lasfile, \"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berridale201802-LID2-C3-AHD_6585974_55_0002_0002\n",
      "../../vh/Berridale201802-LID2-C3-AHD_6585974_55_0002_0002-vh-25m.tiff\n",
      "../../vcf/Berridale201802-LID2-C3-AHD_6585974_55_0002_0002-vcf-25m.tiff\n",
      "../../cth/Berridale201802-LID2-C3-AHD_6585974_55_0002_0002-cth-25m.tiff\n",
      "../../cbh/Berridale201802-LID2-C3-AHD_6585974_55_0002_0002-cbh-25m.tiff\n",
      "../../fbf/Berridale201802-LID2-C3-AHD_6585974_55_0002_0002-fbf-25m.tiff\n",
      "../../cli/Berridale201802-LID2-C3-AHD_6585974_55_0002_0002-cli-25m.tiff\n",
      "../../lcf_h/Berridale201802-LID2-C3-AHD_6585974_55_0002_0002-lcf_h-25m.tiff\n",
      "../../lcf_os/Berridale201802-LID2-C3-AHD_6585974_55_0002_0002-lcf_os-25m.tiff\n",
      "../../lcf_us/Berridale201802-LID2-C3-AHD_6585974_55_0002_0002-lcf_us-25m.tiff\n",
      "../../lcf_cf/Berridale201802-LID2-C3-AHD_6585974_55_0002_0002-lcf_cf-25m.tiff\n",
      "../../lcf_ef/Berridale201802-LID2-C3-AHD_6585974_55_0002_0002-lcf_ef-25m.tiff\n",
      "../../lcf_nsf/Berridale201802-LID2-C3-AHD_6585974_55_0002_0002-lcf_nsf-25m.tiff\n",
      "../../density/Berridale201802-LID2-C3-AHD_6585974_55_0002_0002-density-25m.tiff\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#write some rasters\n",
    "\n",
    "export_tern_products(tern_products, metadata, resolution, lasfile, \"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#produce some rasters!\n",
    "\n",
    "tern_products = compute_tern_products(metadata, df, sindex, resolution, lasfile, \"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "export_tern_products(tern_products, metadata, resolution, lasfile, \"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tern_products.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.rot90(tern_products[\"vcf\"]))\n",
    "plt.colorbar()\n",
    "plt.title(\"Vegetation cover fraction (VCF)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.rot90(tern_products[\"cth\"]), vmin = 0)\n",
    "plt.colorbar()\n",
    "plt.title(\"Canopy top height (CTH)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.rot90(tern_products[\"cbh\"]), vmin = 0)\n",
    "plt.colorbar()\n",
    "plt.title(\"Canopy base height (CBH)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.rot90(tern_products[\"cth\"] -tern_products[\"cbh\"]))\n",
    "plt.colorbar()\n",
    "plt.title(\"Canopy top and base height difference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.rot90(tern_products[\"fbf\"]))\n",
    "plt.colorbar()\n",
    "plt.title(\"Building fraction (FBF)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.rot90(tern_products[\"cli\"]))\n",
    "plt.colorbar()\n",
    "plt.title(\"Canopy Layering Index (CLI)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.rot90(tern_products[\"lcf_h\"]))\n",
    "plt.colorbar()\n",
    "plt.title(\"LCF_H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.rot90(tern_products[\"lcf_os\"]))\n",
    "plt.colorbar()\n",
    "plt.title(\"LCF_OS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.rot90(tern_products[\"lcf_us\"]))\n",
    "plt.colorbar()\n",
    "plt.title(\"LCF_US\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.rot90(tern_products[\"lcf_cf\"]))\n",
    "plt.colorbar()\n",
    "plt.title(\"LCF_CF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.rot90(tern_products[\"density\"]))\n",
    "plt.colorbar()\n",
    "plt.title(\"density\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygons = forestutils.gen_raster_cells(metadata, resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygons[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = forestutils.get_cell_points(polygons[55], df, sindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.comp_cli(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.comp_density(matches, resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## code purgatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# an attempt at building an index without pandas. Pandas was far easier...\n",
    "\n",
    "## rtree index building straight from the point dataset... which also duplicates the point set...\n",
    "# I think this is a pretty slow way... if we're looping over points might as well process them\n",
    "# at the same time...\n",
    "idx = index.Index()\n",
    "for pid, point in enumerate(points[0]):\n",
    "    idx.insert(pid, (point[0], point[1], point[0], point[1]), point)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for raster writing later..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up GDAL parameters\n",
    "    \n",
    "    wktcrs = metadata[\"metadata\"][\"readers.las\"][\"comp_spatialreference\"]\n",
    "    \n",
    "    raster_parameters = {}\n",
    "    raster_parameters[\"width\"] = np.shape(vcf_raster)[0]\n",
    "    raster_parameters[\"height\"] = np.shape(vcf_raster)[1]\n",
    "    raster_parameters[\"upperleft_x\"] = metadata[\"metadata\"][\"readers.las\"][\"minx\"]\n",
    "    raster_parameters[\"upperleft_y\"] = metadata[\"metadata\"][\"readers.las\"][\"maxy\"]\n",
    "    raster_parameters[\"resolution\"] = resolution\n",
    "    raster_parameters[\"projection\"] = wktcrs\n",
    "    \n",
    "    fileroot = forestutils.make_file_rootname(lasfile)\n",
    "    print(fileroot)\n",
    "    \n",
    "    if (not os.path.isdir(outpath + \"/vcf\")):\n",
    "        os.mkdir(outpath + \"/vcf\")\n",
    "    if (not os.path.isdir(outpath + \"/cth\")):\n",
    "        os.mkdir(outpath + \"/cth\")\n",
    "    if (not os.path.isdir(outpath + \"/cbh\")):\n",
    "        os.mkdir(outpath + \"/cbh\")\n",
    "    if (not os.path.isdir(outpath + \"/fbf\")):\n",
    "        os.mkdir(outpath + \"/fbf\")\n",
    "    if (not os.path.isdir(outpath + \"/cli\")):\n",
    "        os.mkdir(outpath + \"/cli\")\n",
    "        \n",
    "    #lcf will hold 3 output rasters\n",
    "    if (not os.path.isdir(outpath + \"/lcf\")):\n",
    "        os.mkdir(outpath + \"/lcf\")\n",
    "\n",
    "\n",
    "    \n",
    "    #set output filenames\n",
    "    vcf_raster_path = os.path.join(outpath,\n",
    "                                   \"vcf\",\n",
    "                                   fileroot + \"-VCF-\" + str(resolution) + \"m.tiff\")\n",
    "    \n",
    "    print(vcf_raster_path)\n",
    "    cth_raster_path = outpath + \"/cth/\" + fileroot + \"-CTH-\" + str(resolution) + \"m.tiff\"\n",
    "    cbh_raster_path = outpath + \"/cbh/\" + fileroot + \"-CBH-\" + str(resolution) + \"m.tiff\"\n",
    "    fbf_raster_path = outpath + \"/fbf/\" + fileroot + \"-FBF-\" + str(resolution) + \"m.tiff\"\n",
    "    cli_raster_path = outpath + \"/cli/\" + fileroot + \"-CLI-\" + str(resolution) + \"m.tiff\"\n",
    "\n",
    "\n",
    "    #write geotiffs and return arrays for inspection...\n",
    "    \n",
    "    #TO DO:\n",
    "    # - density\n",
    "    # - lcf products\n",
    "\n",
    "    forestutils.write_product_geotiff(vcf_raster, vcf_raster_path, raster_parameters)\n",
    "    forestutils.write_product_geotiff(cth_raster, cth_raster_path, raster_parameters)\n",
    "    forestutils.write_product_geotiff(cbh_raster, cbh_raster_path, raster_parameters)\n",
    "    forestutils.write_product_geotiff(fbf_raster, fbf_raster_path, raster_parameters)\n",
    "    forestutils.write_product_geotiff(cli_raster, cli_raster_path, raster_parameters)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
