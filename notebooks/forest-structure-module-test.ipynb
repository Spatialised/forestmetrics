{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forest structure using PDAL + Python\n",
    "\n",
    "Dr Adam Steer, November 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NODATA_VALUE = -9999\n",
    "LCF_HEIGHTS = [0, 0.05, 0.5, 1, 2, 3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pdal\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry import MultiPolygon\n",
    "from shapely.geometry import box\n",
    "#from shapely.strtree import STRtree\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import osmnx as ox\n",
    "\n",
    "import os\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('../'))\n",
    "sys.path.insert(0, os.path.abspath('../../callingelvis'))\n",
    "\n",
    "# not using this, using geopandas instead\n",
    "from rtree import index\n",
    "\n",
    "# this is needed to create a raster from the output array\n",
    "from osgeo import gdal\n",
    "import osgeo.osr as osr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from callingelvis import anybodyhome\n",
    "\n",
    "import forestmetrics.forestmetrics as metrics\n",
    "import forestmetrics.utils as forestutils\n",
    "\n",
    "#import forestpipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tern_products(metadata, points, sindex, resolution, lasfile, outpath):\n",
    "    \"\"\"\n",
    "    Wrapper to iterate over the input data and generate rasters for each product.\n",
    "    \n",
    "    *note this part could be paralellised - maybe per-product, or per-cell\n",
    "    \n",
    "    Each grid square processed in this loop corresponds to one pixel in an output raster.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #set up an 'output resolution' sized grid - like a fishnet grid.\n",
    "    # each polygon in the resulting set covers an area of 'resolution X resolution'\n",
    "    pixel_grid = forestutils.gen_raster_cells(metadata, resolution)\n",
    "    \n",
    "    #set up output rasters\n",
    "    \n",
    "    # get tile width and height\n",
    "    tile_width = metadata[\"metadata\"][\"readers.las\"][\"maxx\"] - metadata[\"metadata\"][\"readers.las\"][\"minx\"]\n",
    "    tile_height = metadata[\"metadata\"][\"readers.las\"][\"maxy\"] - metadata[\"metadata\"][\"readers.las\"][\"miny\"]\n",
    "\n",
    "    raster_xsize = int(np.ceil(tile_width) / resolution)\n",
    "    raster_ysize = int(np.ceil(tile_height) / resolution)\n",
    "    \n",
    "    #replicate for all products...\n",
    "    vcf_raster = np.zeros((raster_xsize, raster_ysize))\n",
    "    cth_raster = np.zeros((raster_xsize, raster_ysize))\n",
    "    cbh_raster = np.zeros((raster_xsize, raster_ysize))\n",
    "    fbf_raster = np.zeros((raster_xsize, raster_ysize))\n",
    "    cli_raster = np.zeros((raster_xsize, raster_ysize))\n",
    "    \n",
    "    veg_below_dict = {}\n",
    "\n",
    "    veg_below_dict[\"all\"] = np.zeros((raster_xsize, raster_ysize))\n",
    "    for height in LCF_HEIGHTS:\n",
    "        veg_below_dict[str(height)] = np.zeros((raster_xsize, raster_ysize))\n",
    "    \n",
    "    #internal loop around grid squares covering the LAS tile.\n",
    "    # this is another ppoint for parallelisation - since we can set up a list of geometries\n",
    "    # and cast that at multipuple processes, setting up one process per grid square\n",
    "    # another way to do this would be to recast this loop block into a function which can  \n",
    "    # be called by one process per product\n",
    "    # the second strategy seems easier, then only one process is trying to write into each\n",
    "    # output array.\n",
    "    \n",
    "    for pixel in pixel_grid:\n",
    "        \n",
    "        #compute output array index for this cell:\n",
    "        poly_x, poly_y = pixel.centroid.xy\n",
    "        \n",
    "        poly_base_x = poly_x[0] - metadata[\"metadata\"][\"readers.las\"][\"minx\"]\n",
    "        poly_base_y = poly_y[0] - metadata[\"metadata\"][\"readers.las\"][\"miny\"]\n",
    "        \n",
    "        array_x = int(np.floor((poly_base_x / (resolution)) ))\n",
    "        array_y = int(np.floor((poly_base_y / (resolution)) ))\n",
    "                \n",
    "        #get points for this cell\n",
    "        matches = forestutils.get_cell_points(pixel, points, sindex)\n",
    "        \n",
    "        #compute in order\n",
    "        #VCF\n",
    "        vcf_raster[array_x, array_y] = metrics.comp_vcf(matches)\n",
    "        \n",
    "        #LCF - long-ish process..\n",
    "        # compute a dictionary of points below height thresholds\n",
    "        veg_below = metrics.comp_veg_layers(matches, LCF_HEIGHTS)\n",
    "        \n",
    "        # add the first element of the dictionary to a raster output\n",
    "        veg_below_dict[\"all\"][array_x, array_y] = veg_below[\"all\"]\n",
    "        \n",
    "        #iterate over the height thresholds and do likewise...\n",
    "        for height in LCF_HEIGHTS:\n",
    "            veg_below_dict[str(height)][array_x, array_y] = veg_below[str(height)]\n",
    "        \n",
    "        #CTH\n",
    "        cth_raster[array_x, array_y] = metrics.comp_cth(matches)\n",
    "        \n",
    "        #CBH\n",
    "        cbh_raster[array_x, array_y] = metrics.comp_cbh(matches)\n",
    "        \n",
    "        #FBF\n",
    "        fbf_raster[array_x, array_y] = metrics.comp_fbf(matches)\n",
    "        \n",
    "        #CLI\n",
    "        cli_raster[array_x, array_y] = metrics.comp_cli(matches)\n",
    "        \n",
    "        #density\n",
    "        density_raster[array_x, array_y] = metrics.comp_density(matches)\n",
    "        \n",
    "        \n",
    "        \n",
    "    #end of computing stuff, time to make outputs...\n",
    "    \n",
    "    #compute LCF values given our height thresholded veg counts\n",
    "    lcf = metrics.comp_lcf(veg_below_dict, vcf_raster)\n",
    "    \n",
    "    dem = forestutils.comp_dem(lasfile,  outpath, resolution)\n",
    "    \n",
    "    #set up GDAL parameters\n",
    "    \n",
    "    wktcrs = metadata[\"metadata\"][\"readers.las\"][\"comp_spatialreference\"]\n",
    "    \n",
    "    raster_parameters = {}\n",
    "    raster_parameters[\"width\"] = np.shape(vcf_raster)[0]\n",
    "    raster_parameters[\"height\"] = np.shape(vcf_raster)[1]\n",
    "    raster_parameters[\"upperleft_x\"] = metadata[\"metadata\"][\"readers.las\"][\"minx\"]\n",
    "    raster_parameters[\"upperleft_y\"] = metadata[\"metadata\"][\"readers.las\"][\"maxy\"]\n",
    "    raster_parameters[\"resolution\"] = resolution\n",
    "    raster_parameters[\"projection\"] = wktcrs\n",
    "    \n",
    "    if (not os.path.isdir(outpath + \"/vcf\")):\n",
    "        os.mkdir(outpath + \"/vcf\")\n",
    "    if (not os.path.isdir(outpath + \"/cth\")):\n",
    "        os.mkdir(outpath + \"/cth\")\n",
    "    if (not os.path.isdir(outpath + \"/cbh\")):\n",
    "        os.mkdir(outpath + \"/cbh\")\n",
    "    if (not os.path.isdir(outpath + \"/fbf\")):\n",
    "        os.mkdir(outpath + \"/fbf\")\n",
    "    if (not os.path.isdir(outpath + \"/cli\")):\n",
    "        os.mkdir(outpath + \"/cli\")\n",
    "        \n",
    "    #lcf will hold 3 output rasters\n",
    "    if (not os.path.isdir(outpath + \"/lcf\")):\n",
    "        os.mkdir(outpath + \"/lcf\")\n",
    "        \n",
    "    fileroot = forestutils.make_file_rootname(lasfile)\n",
    "\n",
    "    #set output filenames\n",
    "    vcf_raster_path = outpath + \"/vcf/\" + fileroot + \"-VCF-\" + str(resolution) + \"m.tiff\"\n",
    "    cth_raster_path = outpath + \"/cth/\" + fileroot + \"-CTH-\" + str(resolution) + \"m.tiff\"\n",
    "    cbh_raster_path = outpath + \"/cbh/\" + fileroot + \"-CBH-\" + str(resolution) + \"m.tiff\"\n",
    "    fbf_raster_path = outpath + \"/fbf/\" + fileroot + \"-FBF-\" + str(resolution) + \"m.tiff\"\n",
    "    cli_raster_path = outpath + \"/cli/\" + fileroot + \"-CLI-\" + str(resolution) + \"m.tiff\"\n",
    "\n",
    "\n",
    "    #write geotiffs and return arrays for inspection...\n",
    "    \n",
    "    #TO DO:\n",
    "    # - density\n",
    "    # - lcf products\n",
    "\n",
    "    forestutils.write_product_geotiff(vcf_raster, vcf_raster_path, raster_parameters)\n",
    "    forestutils.write_product_geotiff(cth_raster, cth_raster_path, raster_parameters)\n",
    "    forestutils.write_product_geotiff(cbh_raster, cbh_raster_path, raster_parameters)\n",
    "    forestutils.write_product_geotiff(fbf_raster, fbf_raster_path, raster_parameters)\n",
    "    forestutils.write_product_geotiff(cli_raster, cli_raster_path, raster_parameters)\n",
    "    \n",
    "    tern_products = {}\n",
    "    tern_products[\"vcf\"] = vcf_raster\n",
    "    tern_products[\"cth\"] = cth_raster\n",
    "    tern_products[\"cbh\"] = cbh_raster\n",
    "    tern_products[\"fbf\"] = fbf_raster\n",
    "    tern_products[\"cli\"] = cli_raster\n",
    "    tern_products[\"lcf_h\"] = lcf[\"lcf_h\"]\n",
    "    tern_products[\"lcf_os\"] = lcf[\"lcf_os\"]\n",
    "    tern_products[\"lcf_us\"] = lcf[\"lcf_us\"]\n",
    "    tern_products[\"lcf_cf\"] = lcf[\"lcf_cf\"]\n",
    "    tern_products[\"lcf_ef\"] = lcf[\"lcf_ef\"]\n",
    "    tern_products[\"lcf_nsf\"] = lcf[\"lcf_nsf\"]\n",
    "\n",
    "    return(tern_products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing functionality using a local file\n",
    "The following section generates metrics from a local LAZ file. Plugging in download mechanics from ELVIS will be added later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lidar test file - Mt Ainslie, chosen for varied vegetation cover and topography\n",
    "# this is pretty big, try it out if you've got more resources than my macbook pro!\n",
    "\n",
    "# thinking ahead, there will probably end up being a file splitting pre-process for \n",
    "# tiles like these... capping at say, 20 mill points. Sorting data before splitting\n",
    "# will be essential.\n",
    "\n",
    "#lasfile = \"/Volumes/Antares/ACT-lidar/8ppm/callingelvis-testdata/ACT2015_8ppm-C3-AHD_6966094_55.laz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lasfile = \"/Volumes/Antares/fire-test/NSW Government - Spatial Services-2/Point Clouds/AHD/StAlbans201709-LID2-C3-AHD_2866308_56_0002_0002/StAlbans201709-LID2-C3-AHD_2866308_56_0002_0002.las\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasfile = \"../../callingelvis-sampledata/Berridale201802-LID2-C3-AHD_6585974_55_0002_0002.las\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump everything from memory\n",
    "points = None\n",
    "df = None\n",
    "vcf_raster = None\n",
    "cth_raster = None\n",
    "fbf_raster = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = forestutils.readlasmetadata(lasfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.64 s, sys: 143 ms, total: 7.79 s\n",
      "Wall time: 7.76 s\n",
      "CPU times: user 7.64 s, sys: 143 ms, total: 7.79 s\n",
      "Wall time: 7.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# this part of the process is simply reading from the source file. No analysis yet.\n",
    "\n",
    "points = forestutils.readlasfile(lasfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to examine LAS metadata\n",
    "#metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 27s, sys: 547 ms, total: 1min 27s\n",
      "Wall time: 1min 27s\n",
      "CPU times: user 1min 27s, sys: 547 ms, total: 1min 27s\n",
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#here we read points into a GeoDataFrame and dump the labelled array.\n",
    "# this is a pretty expensive step RAM wise, we're duplicating all the points...\n",
    "\n",
    "df = forestutils.pdal2df(points)\n",
    "\n",
    "# set the points structured array to None, it isn't used anymore\n",
    "points = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# here we generate an RTree index on the dataframe using GeoPandas.\n",
    "# also pretty expensive... \n",
    "\n",
    "sindex = forestutils.spatialindex(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set an output resolution\n",
    "\n",
    "resolution = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[\"metadata\"][\"readers.las\"][\"minx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#produce some rasters!\n",
    "\n",
    "tern_products = compute_tern_products(metadata, df, sindex, resolution, lasfile, \"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.rot90(tern_products[\"vcf\"]))\n",
    "plt.colorbar()\n",
    "plt.title(\"Vegetation cover fraction (VCF)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.rot90(tern_products[\"cth\"]), vmin = 0)\n",
    "plt.colorbar()\n",
    "plt.title(\"Canopy top height (CTH)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.rot90(tern_products[\"cbh\"]), vmin = 0)\n",
    "plt.colorbar()\n",
    "plt.title(\"Canopy base height (CBH)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.rot90(tern_products[\"cth\"] -tern_products[\"cbh\"]))\n",
    "plt.colorbar()\n",
    "plt.title(\"Canopy top and base height difference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.rot90(tern_products[\"fbf\"]))\n",
    "plt.colorbar()\n",
    "plt.title(\"Building fraction (FBF)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.rot90(tern_products[\"cli\"]))\n",
    "plt.colorbar()\n",
    "plt.title(\"Canopy Layering Index (CLI)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.rot90(tern_products[\"lcf_h\"]))\n",
    "plt.colorbar()\n",
    "plt.title(\"LCF_H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.rot90(tern_products[\"lcf_os\"]))\n",
    "plt.colorbar()\n",
    "plt.title(\"LCF_OS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.rot90(tern_products[\"lcf_us\"]))\n",
    "plt.colorbar()\n",
    "plt.title(\"LCF_US\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.rot90(tern_products[\"lcf_cf\"]))\n",
    "plt.colorbar()\n",
    "plt.title(\"LCF_CF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tern_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygons = forestutils.gen_raster_cells(metadata, resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygons[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = forestutils.get_cell_points(polygons[55], df, sindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.comp_cli(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.comp_density(matches, resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## code purgatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# an attempt at building an index without pandas. Pandas was far easier\n",
    "\"\"\"\n",
    "%%time\n",
    "\n",
    "\n",
    "## rtree index building straight from the point dataset... which also duplicates the point set...\n",
    "\n",
    "idx = index.Index()\n",
    "for pid, point in enumerate(points[0]):\n",
    "    idx.insert(pid, (point[0], point[1],point[0], point[1]), point)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
